import asyncio
import csv
import json
import logging
import os
import random
import sqlite3
import sys
import time
import argparse
import webbrowser
from contextlib import asynccontextmanager, contextmanager
from dataclasses import dataclass, asdict, field
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import List, Dict, Any, Optional, Set, Tuple, Union, AsyncGenerator, Callable
from functools import wraps

# -----------------------------------------------------------------------------
# ä¾èµ–æ£€æŸ¥ä¸å¯¼å…¥
# -----------------------------------------------------------------------------
try:
    import aiohttp
    import yaml
    from tqdm.asyncio import tqdm
except ImportError as e:
    print(f"CRITICAL ERROR: ç¼ºå°‘å¿…è¦ä¾èµ–åº“: {e.name}")
    print("è¯·è¿è¡Œ: pip install aiohttp tqdm PyYAML")
    sys.exit(1)

# -----------------------------------------------------------------------------
# é…ç½®ä¸å¸¸é‡ (Configuration)
# -----------------------------------------------------------------------------
@dataclass
class AppConfig:
    """åº”ç”¨ç¨‹åºé…ç½®å®¹å™¨"""
    github_token: str
    db_path: str = "data/github_insight.db"
    report_path: str = "reports/insight_report.html"
    lookback_days: int = 30
    concurrency: int = 5
    log_level: str = "INFO"
    
    # å¸¸é‡å®šä¹‰
    GITHUB_API_BASE: str = "https://api.github.com"
    NOMINATIM_API: str = "https://nominatim.openstreetmap.org/search"
    USER_AGENT: str = "GitHub-Insight-Pro/2.0 (Research Purpose)"

# -----------------------------------------------------------------------------
# æ—¥å¿—ç³»ç»Ÿ (Logging)
# -----------------------------------------------------------------------------
def setup_logging(level_name: str) -> logging.Logger:
    """é…ç½®å…¨å±€æ—¥å¿—ç³»ç»Ÿ"""
    level = getattr(logging, level_name.upper(), logging.INFO)
    logger = logging.getLogger("GHInsight")
    logger.setLevel(level)
    
    if not logger.handlers:
        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - [%(levelname)s] - %(message)s',
            datefmt='%H:%M:%S'
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)
    
    return logger

logger = setup_logging("INFO")

# -----------------------------------------------------------------------------
# å·¥å…·å‡½æ•° (Utilities)
# -----------------------------------------------------------------------------
def async_retry(retries: int = 3, delay: int = 1, backoff: int = 2):
    """å¼‚æ­¥é‡è¯•è£…é¥°å™¨ï¼Œæ”¯æŒæŒ‡æ•°é€€é¿"""
    def decorator(func: Callable):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_delay = delay
            for i in range(retries + 1):
                try:
                    return await func(*args, **kwargs)
                except (aiohttp.ClientError, asyncio.TimeoutError) as e:
                    if i == retries:
                        logger.error(f"å‡½æ•° {func.__name__} é‡è¯•è€—å°½: {str(e)}")
                        raise
                    logger.warning(f"è¯·æ±‚å¤±è´¥ ({i+1}/{retries})ï¼Œ{current_delay}s åé‡è¯•: {str(e)}")
                    await asyncio.sleep(current_delay)
                    current_delay *= backoff
        return wrapper
    return decorator

# -----------------------------------------------------------------------------
# æ•°æ®æ¨¡å‹ (Data Models)
# -----------------------------------------------------------------------------
@dataclass
class CommitRecord:
    """æäº¤è®°å½•å®ä½“"""
    sha: str
    repo_name: str
    author_login: str
    timestamp: int
    raw_location: Optional[str] = None
    country_code: str = "UNKNOWN"
    city: str = ""
    lat: float = 0.0
    lon: float = 0.0

    @property
    def commit_date(self) -> datetime:
        return datetime.fromtimestamp(self.timestamp, tz=timezone.utc)

# -----------------------------------------------------------------------------
# æŒä¹…åŒ–å±‚ (Storage Layer)
# -----------------------------------------------------------------------------
class StorageManager:
    """è´Ÿè´£æ‰€æœ‰ SQLite æ•°æ®åº“æ“ä½œ"""
    
    def __init__(self, db_path: str):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self._init_schema()

    def _get_conn(self) -> sqlite3.Connection:
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        return conn

    def _init_schema(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
        with self._get_conn() as conn:
            # 1. åœ°ç†ç¼–ç ç¼“å­˜è¡¨
            conn.execute("""
                CREATE TABLE IF NOT EXISTS geo_cache (
                    raw_text TEXT PRIMARY KEY,
                    country_code TEXT,
                    city TEXT,
                    lat REAL,
                    lon REAL,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            # 2. æäº¤è®°å½•è¡¨ (æ ¸å¿ƒæ•°ä»“)
            conn.execute("""
                CREATE TABLE IF NOT EXISTS commits (
                    sha TEXT PRIMARY KEY,
                    repo_name TEXT,
                    author_login TEXT,
                    timestamp INTEGER,
                    country_code TEXT,
                    lat REAL,
                    lon REAL
                )
            """)
            # ç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢é€Ÿåº¦
            conn.execute("CREATE INDEX IF NOT EXISTS idx_commits_country ON commits(country_code)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_commits_author ON commits(author_login)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_commits_time ON commits(timestamp)")

    def get_geo_cache(self, raw_text: str) -> Optional[Dict[str, Any]]:
        if not raw_text: return None
        with self._get_conn() as conn:
            cursor = conn.execute(
                "SELECT country_code, city, lat, lon FROM geo_cache WHERE raw_text = ?", 
                (raw_text,)
            )
            row = cursor.fetchone()
            return dict(row) if row else None

    def save_geo_cache(self, raw_text: str, data: Dict[str, Any]):
        with self._get_conn() as conn:
            conn.execute(
                """INSERT OR REPLACE INTO geo_cache (raw_text, country_code, city, lat, lon) 
                   VALUES (?, ?, ?, ?, ?)""",
                (raw_text, data.get('country_code'), data.get('city'), data.get('lat'), data.get('lon'))
            )

    def is_commit_exists(self, sha: str) -> bool:
        with self._get_conn() as conn:
            cursor = conn.execute("SELECT 1 FROM commits WHERE sha = ?", (sha,))
            return cursor.fetchone() is not None

    def save_commits(self, commits: List[CommitRecord]):
        if not commits: return
        data = [
            (c.sha, c.repo_name, c.author_login, c.timestamp, c.country_code, c.lat, c.lon)
            for c in commits
        ]
        with self._get_conn() as conn:
            conn.executemany(
                "INSERT OR IGNORE INTO commits VALUES (?, ?, ?, ?, ?, ?, ?)", 
                data
            )

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç”¨äºæŠ¥å‘Šç”Ÿæˆçš„ç»Ÿè®¡æ•°æ®"""
        stats = {}
        with self._get_conn() as conn:
            # å›½å®¶åˆ†å¸ƒ
            cur = conn.execute("""
                SELECT country_code, COUNT(*) as cnt 
                FROM commits 
                WHERE country_code != 'UNKNOWN' AND country_code != '' 
                GROUP BY country_code 
                ORDER BY cnt DESC 
                LIMIT 20
            """)
            stats['countries'] = {row['country_code']: row['cnt'] for row in cur.fetchall()}

            # æ´»è·ƒæ—¶é—´ (UTC)
            cur = conn.execute("""
                SELECT strftime('%H', datetime(timestamp, 'unixepoch')) as hour, COUNT(*) as cnt
                FROM commits 
                GROUP BY hour
                ORDER BY hour
            """)
            stats['hourly'] = {row['hour']: row['cnt'] for row in cur.fetchall()}

            # é¡¶çº§è´¡çŒ®è€…
            cur = conn.execute("""
                SELECT author_login, COUNT(*) as cnt 
                FROM commits 
                GROUP BY author_login 
                ORDER BY cnt DESC 
                LIMIT 10
            """)
            stats['top_devs'] = {row['author_login']: row['cnt'] for row in cur.fetchall()}
            
            # æ€»è§ˆæ•°æ®
            stats['total_commits'] = conn.execute("SELECT COUNT(*) FROM commits").fetchone()[0]
            stats['total_devs'] = conn.execute("SELECT COUNT(DISTINCT author_login) FROM commits").fetchone()[0]

        return stats

# -----------------------------------------------------------------------------
# æœåŠ¡å±‚ (Service Layer)
# -----------------------------------------------------------------------------
class GeoService:
    """å¤„ç†åœ°ç†ç¼–ç é€»è¾‘ï¼ŒåŒ…å«ç¼“å­˜ç­–ç•¥"""
    
    def __init__(self, session: aiohttp.ClientSession, storage: StorageManager, config: AppConfig):
        self.session = session
        self.storage = storage
        self.config = config
        # Nominatim ä¸¥æ ¼é™åˆ¶æ¯ç§’ 1 æ¬¡è¯·æ±‚ï¼Œè¿™é‡Œä½¿ç”¨ Semaphore æ§åˆ¶
        self._rate_limiter = asyncio.Semaphore(1)

    async def resolve(self, location_str: str) -> Dict[str, Any]:
        """è§£æä½ç½®å­—ç¬¦ä¸²ï¼Œä¼˜å…ˆè¯»ç¼“å­˜ï¼Œå¤±è´¥åˆ™è°ƒç”¨ API"""
        empty_res = {"country_code": "UNKNOWN", "city": "", "lat": 0.0, "lon": 0.0}
        
        if not location_str or not location_str.strip():
            return empty_res

        # 1. æŸ¥ç¼“å­˜
        cached = self.storage.get_geo_cache(location_str)
        if cached:
            return cached

        # 2. è°ƒç”¨ API
        return await self._fetch_from_api(location_str)

    @async_retry(retries=2, delay=2)
    async def _fetch_from_api(self, query: str) -> Dict[str, Any]:
        async with self._rate_limiter:
            # éµå®ˆ Nominatim ä½¿ç”¨ç­–ç•¥ï¼šå¿…é¡»åŒ…å« User-Agentï¼Œé™åˆ¶é€Ÿç‡
            params = {"q": query, "format": "json", "limit": 1, "accept-language": "en"}
            headers = {"User-Agent": self.config.USER_AGENT}
            
            async with self.session.get(self.config.NOMINATIM_API, params=params, headers=headers) as resp:
                if resp.status != 200:
                    logger.warning(f"GeoAPI é”™è¯¯ {resp.status}: {query}")
                    return {"country_code": "UNKNOWN", "city": "", "lat": 0.0, "lon": 0.0}
                
                data = await resp.json()
                await asyncio.sleep(1.1) # å¼ºåˆ¶å†·å´ï¼Œç¡®ä¿ä¸è¶…è¿‡ 1 RPS

                result = {"country_code": "UNKNOWN", "city": "unknown", "lat": 0.0, "lon": 0.0}
                
                if data:
                    item = data[0]
                    display_name = item.get("display_name", "")
                    # ç®€å•çš„å¯å‘å¼è§£æå›½å®¶ä»£ç 
                    parts = display_name.split(",")
                    country_code = parts[-1].strip().upper()[:3] if parts else "UNKNOWN"
                    
                    result = {
                        "country_code": country_code,
                        "city": item.get("type", "unknown"),
                        "lat": float(item.get("lat", 0)),
                        "lon": float(item.get("lon", 0))
                    }
                
                # å†™å…¥ç¼“å­˜ï¼ˆå³ä½¿æ˜¯ç©ºç»“æœä¹Ÿç¼“å­˜ï¼Œé˜²æ­¢é‡å¤æ— æ•ˆæŸ¥è¯¢ï¼‰
                self.storage.save_geo_cache(query, result)
                return result

class GitHubService:
    """å¤„ç† GitHub API äº¤äº’"""
    
    def __init__(self, session: aiohttp.ClientSession, token: str, config: AppConfig):
        self.session = session
        self.token = token
        self.config = config
        self.base_headers = {
            "Authorization": f"token {token}",
            "Accept": "application/vnd.github.v3+json",
            "User-Agent": config.USER_AGENT
        }

    async def _handle_rate_limit(self, resp: aiohttp.ClientResponse):
        """å¤„ç† GitHub é€Ÿç‡é™åˆ¶"""
        if resp.status == 403 and 'X-RateLimit-Remaining' in resp.headers:
            remaining = int(resp.headers.get('X-RateLimit-Remaining', 1))
            if remaining == 0:
                reset_time = int(resp.headers.get('X-RateLimit-Reset', 0))
                wait_time = max(reset_time - time.time(), 0) + 1
                logger.warning(f"GitHub API é™æµè§¦å‘ï¼Œä¼‘çœ  {wait_time:.0f} ç§’...")
                await asyncio.sleep(wait_time)
                return True
        return False

    @async_retry()
    async def get_user_location(self, username: str) -> str:
        url = f"{self.config.GITHUB_API_BASE}/users/{username}"
        async with self.session.get(url, headers=self.base_headers) as resp:
            if await self._handle_rate_limit(resp):
                return await self.get_user_location(username) # Retry logic handles recursion depth implicitly via decorator
            if resp.status == 404:
                return ""
            data = await resp.json()
            return data.get("location") or ""

    async def fetch_commits(self, repo: str, since: datetime) -> AsyncGenerator[List[Dict], None]:
        """ç”Ÿæˆå™¨æ¨¡å¼è·å– Commit æ‰¹æ¬¡"""
        url = f"{self.config.GITHUB_API_BASE}/repos/{repo}/commits"
        params = {"since": since.isoformat(), "per_page": 100, "page": 1}
        
        while True:
            try:
                async with self.session.get(url, headers=self.base_headers, params=params) as resp:
                    if await self._handle_rate_limit(resp):
                        continue # Retry same page
                    
                    if resp.status != 200:
                        logger.error(f"è·å– {repo} å¤±è´¥: HTTP {resp.status}")
                        break
                        
                    batch = await resp.json()
                    if not batch or not isinstance(batch, list):
                        break
                        
                    yield batch
                    
                    if len(batch) < 100:
                        break
                    params["page"] += 1
            except Exception as e:
                logger.error(f"Fetch loop error: {e}")
                break

# -----------------------------------------------------------------------------
# æ ¸å¿ƒé€»è¾‘æ§åˆ¶å™¨ (Controller)
# -----------------------------------------------------------------------------
class InsightEngine:
    """ä¸»é€»è¾‘ç¼–æ’å¼•æ“"""
    
    def __init__(self, config: AppConfig):
        self.config = config
        self.storage = StorageManager(config.db_path)
    
    async def run(self, projects: List[str]):
        """æ‰§è¡Œä¸»ä»»åŠ¡æµç¨‹"""
        conn = aiohttp.TCPConnector(limit=self.config.concurrency)
        async with aiohttp.ClientSession(connector=conn) as session:
            self.gh_service = GitHubService(session, self.config.github_token, self.config)
            self.geo_service = GeoService(session, self.storage, self.config)
            
            # è®¡ç®—èµ·å§‹æ—¶é—´
            since_date = datetime.now(timezone.utc) - timedelta(days=self.config.lookback_days)
            logger.info(f"å¼€å§‹åˆ†æä»»åŠ¡ - å›æº¯æ—¶é—´: {since_date.date()} - é¡¹ç›®æ•°: {len(projects)}")

            # åˆ›å»ºå¹¶å‘ä»»åŠ¡
            tasks = [self._process_single_repo(p, since_date) for p in projects]
            
            # ä½¿ç”¨ tqdm æ˜¾ç¤ºæ€»ä½“è¿›åº¦
            await tqdm.gather(*tasks, desc="Repositories Analysis", unit="repo")
            
            logger.info("æ‰€æœ‰ä»“åº“åˆ†æå®Œæˆï¼Œç”ŸæˆæŠ¥å‘Šä¸­...")
            self._generate_report()

    async def _process_single_repo(self, repo: str, since: datetime):
        """å¤„ç†å•ä¸ªä»“åº“ï¼šè·å–Commit -> è¿‡æ»¤ -> è¡¥å…¨Geo -> å­˜å‚¨"""
        new_commits_buffer = []
        
        async for batch in self.gh_service.fetch_commits(repo, since):
            for item in batch:
                sha = item['sha']
                
                # è·³è¿‡å·²å¤„ç†æˆ–æ— ä½œè€…ä¿¡æ¯çš„æäº¤
                if self.storage.is_commit_exists(sha) or not item.get('author'):
                    continue
                
                author_login = item['author']['login']
                commit_ts = datetime.fromisoformat(
                    item['commit']['author']['date'].replace("Z", "+00:00")
                ).timestamp()

                # 1. è·å–ç”¨æˆ·ä½ç½® (Raw)
                raw_loc = await self.gh_service.get_user_location(author_login)
                
                # 2. è§£æåœ°ç†ä½ç½® (Geo)
                geo_info = await self.geo_service.resolve(raw_loc)
                
                # 3. æ„å»ºè®°å½•
                record = CommitRecord(
                    sha=sha,
                    repo_name=repo,
                    author_login=author_login,
                    timestamp=int(commit_ts),
                    raw_location=raw_loc,
                    **geo_info
                )
                new_commits_buffer.append(record)
            
            # æ‰¹æ¬¡å†™å…¥æ•°æ®åº“ï¼Œå‡å°‘ IO
            if new_commits_buffer:
                self.storage.save_commits(new_commits_buffer)
                new_commits_buffer.clear()

    def _generate_report(self):
        """è°ƒç”¨æŠ¥å‘Šç”Ÿæˆå™¨"""
        stats = self.storage.get_statistics()
        if not stats.get('total_commits'):
            logger.warning("æ²¡æœ‰é‡‡é›†åˆ°ä»»ä½•æ•°æ®ï¼Œè·³è¿‡æŠ¥å‘Šç”Ÿæˆã€‚")
            return
            
        generator = ReportGenerator(self.config.report_path)
        generator.render(stats)
        
        abs_path = os.path.abspath(self.config.report_path)
        logger.info(f"å¯è§†åŒ–æŠ¥å‘Šå·²ç”Ÿæˆ: file://{abs_path}")
        # webbrowser.open(f"file://{abs_path}") # å¯é€‰ï¼šè‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨

# -----------------------------------------------------------------------------
# æŠ¥å‘Šç”Ÿæˆå™¨ (View Layer)
# -----------------------------------------------------------------------------
class ReportGenerator:
    """ç”Ÿæˆ HTML æŠ¥å‘Š"""
    
    def __init__(self, output_path: str):
        self.output_path = Path(output_path)
        self.output_path.parent.mkdir(parents=True, exist_ok=True)

    def render(self, stats: Dict[str, Any]):
        html_content = self._get_template().format(
            gen_time=datetime.now().strftime('%Y-%m-%d %H:%M'),
            total_commits=stats.get('total_commits', 0),
            total_devs=stats.get('total_devs', 0),
            countries_labels=json.dumps(list(stats['countries'].keys())),
            countries_data=json.dumps(list(stats['countries'].values())),
            hourly_labels=json.dumps(list(stats['hourly'].keys())),
            hourly_data=json.dumps(list(stats['hourly'].values())),
            top_devs_rows=self._render_table_rows(stats['top_devs'])
        )
        
        with open(self.output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)

    def _render_table_rows(self, dev_dict: Dict[str, int]) -> str:
        rows = []
        for rank, (user, count) in enumerate(dev_dict.items(), 1):
            rows.append(
                f"<tr><td>{rank}</td><td><a href='https://github.com/{user}' target='_blank'>{user}</a></td><td>{count}</td></tr>"
            )
        return "".join(rows)

    def _get_template(self) -> str:
        return """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GitHub Insight Pro Report</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        :root {{ --primary: #2563eb; --bg: #f8fafc; --card: #ffffff; --text: #1e293b; }}
        body {{ font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; background: var(--bg); color: var(--text); margin: 0; padding: 20px; }}
        .container {{ max-width: 1200px; margin: 0 auto; }}
        .header {{ text-align: center; margin-bottom: 40px; padding: 20px; background: var(--card); border-radius: 12px; box-shadow: 0 4px 6px -1px rgba(0,0,0,0.1); }}
        .stats-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin-bottom: 30px; }}
        .stat-card {{ background: var(--card); padding: 20px; border-radius: 8px; text-align: center; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }}
        .stat-val {{ font-size: 2em; font-weight: bold; color: var(--primary); }}
        .charts-grid {{ display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-bottom: 30px; }}
        .chart-box {{ background: var(--card); padding: 20px; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.05); }}
        .table-box {{ background: var(--card); padding: 20px; border-radius: 12px; overflow: hidden; }}
        table {{ width: 100%; border-collapse: collapse; }}
        th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #e2e8f0; }}
        th {{ background: #f1f5f9; font-weight: 600; }}
        a {{ color: var(--primary); text-decoration: none; }}
        @media (max-width: 768px) {{ .charts-grid {{ grid-template-columns: 1fr; }} }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>GitHub é¡¹ç›®åœ°ç†åˆ†å¸ƒæ´å¯ŸæŠ¥å‘Š</h1>
            <p style="color: #64748b;">ç”Ÿæˆæ—¶é—´: {gen_time}</p>
        </div>

        <div class="stats-grid">
            <div class="stat-card">
                <div class="stat-val">{total_commits}</div>
                <div>åˆ†æ Commit æ€»æ•°</div>
            </div>
            <div class="stat-card">
                <div class="stat-val">{total_devs}</div>
                <div>æ´»è·ƒè´¡çŒ®è€…</div>
            </div>
        </div>

        <div class="charts-grid">
            <div class="chart-box">
                <h3>ğŸŒ è´¡çŒ®è€…å›½å®¶/åœ°åŒºåˆ†å¸ƒ</h3>
                <canvas id="countryChart"></canvas>
            </div>
            <div class="chart-box">
                <h3>â° å…¨çƒæäº¤æ—¶é—´åˆ†å¸ƒ (UTC)</h3>
                <canvas id="hourChart"></canvas>
            </div>
        </div>

        <div class="table-box">
            <h3>ğŸ† æ ¸å¿ƒè´¡çŒ®è€…æ¦œå• (Top 10)</h3>
            <table>
                <thead><tr><th>æ’å</th><th>ç”¨æˆ· ID</th><th>æäº¤æ•°</th></tr></thead>
                <tbody>{top_devs_rows}</tbody>
            </table>
        </div>
    </div>

    <script>
        const commonOptions = {{ responsive: true, plugins: {{ legend: {{ position: 'bottom' }} }} }};
        
        new Chart(document.getElementById('countryChart'), {{
            type: 'bar',
            data: {{
                labels: {countries_labels},
                datasets: [{{
                    label: 'Commits',
                    data: {countries_data},
                    backgroundColor: '#3b82f6',
                    borderRadius: 4
                }}]
            }},
            options: commonOptions
        }});

        new Chart(document.getElementById('hourChart'), {{
            type: 'line',
            data: {{
                labels: {hourly_labels},
                datasets: [{{
                    label: 'Activity Volume',
                    data: {hourly_data},
                    borderColor: '#ef4444',
                    backgroundColor: 'rgba(239, 68, 68, 0.1)',
                    fill: true,
                    tension: 0.4
                }}]
            }},
            options: commonOptions
        }});
    </script>
</body>
</html>
"""

# -----------------------------------------------------------------------------
# ç¨‹åºå…¥å£ (Entry Point)
# -----------------------------------------------------------------------------
def load_projects_from_config(config_path: str) -> List[str]:
    """ä» YAML åŠ è½½é¡¹ç›®åˆ—è¡¨"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)
            return data.get('projects', [])
    except Exception as e:
        logger.error(f"æ— æ³•è¯»å–é…ç½®æ–‡ä»¶ {config_path}: {e}")
        return []

def main():
    parser = argparse.ArgumentParser(description="GitHub Insight Pro - Developer Geography Analyzer")
    parser.add_argument("-p", "--projects", nargs='+', help="GitHub ä»“åº“è·¯å¾„ (e.g. facebook/react)")
    parser.add_argument("-f", "--config", help="YAML é…ç½®æ–‡ä»¶è·¯å¾„åŒ…å«é¡¹ç›®åˆ—è¡¨")
    parser.add_argument("-d", "--days", type=int, default=30, help="åˆ†æè¿‡å»å¤šå°‘å¤©çš„æ•°æ® (é»˜è®¤: 30)")
    parser.add_argument("-o", "--output", default="reports/insight_report.html", help="æŠ¥å‘Šè¾“å‡ºè·¯å¾„")
    parser.add_argument("--db", default="data/github_data.db", help="SQLite æ•°æ®åº“è·¯å¾„")
    
    args = parser.parse_args()
    
    # 1. è·å– Token
    token = os.environ.get("GITHUB_TOKEN")
    if not token:
        logger.critical("æœªæ£€æµ‹åˆ°ç¯å¢ƒå˜é‡ GITHUB_TOKENã€‚è¯·è®¾ç½®åé‡è¯•ã€‚")
        logger.info("Example: export GITHUB_TOKEN=ghp_xxxxxxxxxxxx")
        sys.exit(1)

    # 2. ç¡®å®šé¡¹ç›®åˆ—è¡¨
    projects = []
    if args.projects:
        projects.extend(args.projects)
    if args.config:
        projects.extend(load_projects_from_config(args.config))
    
    # å»é‡å¹¶éªŒè¯
    projects = list(set(p for p in projects if "/" in p))
    
    if not projects:
        logger.error("æœªæŒ‡å®šæœ‰æ•ˆçš„ GitHub é¡¹ç›®ã€‚è¯·ä½¿ç”¨ -p æˆ– -f å‚æ•°ã€‚")
        parser.print_help()
        sys.exit(1)

    # 3. åˆå§‹åŒ–é…ç½®
    config = AppConfig(
        github_token=token,
        db_path=args.db,
        report_path=args.output,
        lookback_days=args.days
    )

    # 4. è¿è¡Œå¼•æ“
    engine = InsightEngine(config)
    
    try:
        asyncio.run(engine.run(projects))
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­æ“ä½œï¼Œæ­£åœ¨å®‰å…¨é€€å‡º...")
    except Exception as e:
        logger.exception(f"ç¨‹åºè¿è¡Œå‘ç”Ÿæœªæ•è·å¼‚å¸¸: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
